{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Text generation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "One very basic kind of text generation model is the Markov model.  In\n",
    "such a model, we have a state which consists of the previous character.\n",
    "We also have a matrix of transitions from one character to another.  We\n",
    "*train* the model by feeding it some text, and observing the\n",
    "transitions.  We can then generate more text from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def train_sentence(transitions, sentence, depth=1):\n",
    "    # We need a \"special\" character to represent the beginning of a sentence.\n",
    "    # This is also the character we'll use to feed the generator, below.\n",
    "    prevchar = \"•\" * depth\n",
    "    for char in sentence:\n",
    "        transitions[prevchar][char] += 1\n",
    "        prevchar = prevchar[1:] + char\n",
    "\n",
    "    return transitions\n",
    "\n",
    "def split_text(text):\n",
    "    for sentence in re.finditer(\".*?([.?!][”’]?|\\n\\n)\", text, re.DOTALL):\n",
    "        # Turn all sequences of whitespace into a single space\n",
    "        sentence = re.sub(\"[ \\t\\n\\r]+\", \" \", sentence.group(0)).strip()\n",
    "        yield sentence\n",
    "\n",
    "def train(filename, depth=1):\n",
    "    transitions = defaultdict(lambda: defaultdict(int))\n",
    "    with open(filename) as fin:\n",
    "        text = fin.read()\n",
    "        for sentence in split_text(text):\n",
    "            if len(sentence) < 3:\n",
    "                continue\n",
    "            transitions = train_sentence(transitions, sentence, depth)\n",
    "\n",
    "    return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_transitions(trs):\n",
    "    rows = []\n",
    "    for key in trs:\n",
    "        for key2 in trs[key]:\n",
    "            rows.append({'from': key, 'to': key2, 'n': trs[key][key2]})\n",
    "    data = pd.DataFrame(rows)\n",
    "    data = data.pivot_table(index='from', columns='to', values='n')\n",
    "    data = data.div(data.sum(axis=1), axis=0)\n",
    "    data[np.isnan(data)] = 0\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def produce(transitions):\n",
    "    if isinstance(transitions, defaultdict):\n",
    "        transitions = format_transitions(transitions)\n",
    "\n",
    "    # Nifty trick: auto-calculate the depth we were trained on\n",
    "    depth = len(transitions.index[0])\n",
    "\n",
    "    output = \"\"\n",
    "    last = \"•\" * depth\n",
    "    nxt = \"\"\n",
    "\n",
    "    while nxt not in [\".\", \"?\", \"!\"]:\n",
    "        trs = transitions.loc[last]\n",
    "        nxt = np.random.choice(trs.index, p=trs)\n",
    "        last = last[1:] + nxt\n",
    "        output += nxt\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tr = train(\"alice.txt\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "produce(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Ideas for extension:\n",
    "\n",
    "- Train on a different text\n",
    "- Try normalizing the text in different ways (e.g. what happens if you take\n",
    "  out quotation marks?)\n",
    "- Play around with different depths.  Do different ones work better for\n",
    "  different texts?\n",
    "- Try generating longer passages (you will need to alter the training\n",
    "  also)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Neural networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "presentation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
